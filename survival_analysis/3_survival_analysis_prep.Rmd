---
title: "survival_analysis_prep"
author: "yacine"
date: "2024-07-16"
output:
  pdf_document: default
  html_document: default
---

We load and/or install the packages we will be using:

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Refresh environment 
rm(list= ls())
library(dplyr)
library(survival)
library(data.table)
library(readr)
library(dvmisc)
library(gtsummary)
library(gt)
library(kableExtra)
library(broom.helpers)
library(flextable)
library(officer)
library(ggplot2)

theme_gtsummary_journal("jama")
```

## We load the data:
```{r}
#full_df <- read.csv("/home/yacine/final_df_full.csv") # full df w/o exclusions
#full_df <- read.csv("/home/yacine/UKBB_beluga/df_exc.csv") # full df with exclusions
full_df <- read.csv("/home/yacine/UKBB_beluga/df_exc_recode.csv") # full df with exclusions + recoding
```



## CVD 
We change the date format for the start and end accelerometer variables - which
will be crucial for later steps:
```{r}
full_df$date_start_accel <- as.Date(full_df$date_start_accel)
full_df$date_end_accel <- as.Date(full_df$date_end_accel)
```




First we create the "end_of_fu" variable, which can be classified as date of 
stroke/MI, date of death or the end of the study (i.e. 2022):

```{r}
# we find out which death date is the latest which we will set as the "end of the study" 
# date
max_death_date_0 <- max(full_df$'date_of_death_0', na.rm = TRUE)
max_death_date_1 <- max(full_df$'date_of_death_1', na.rm = TRUE)
print(max_death_date_0)
print(max_death_date_1)

# given that we see that the max(death_date) is "2022-12-17", this will serve as 
# our "end of study" date

# we create a "end_of_study" column which indicates the end of the whole data collection:
full_df$end_of_study_date <- as.Date('2022-12-17')

# we reate a vector of all the date columns:
date_cols <- c('stroke_date', 'ischaemic_stroke_date', 'intracerebral_haemorrhage_date',
               'myocardial_infarction_date', 'STEMI_date', 'NSTEMI_date',
               'date_of_death_0', 'date_of_death_1', 'date_lost_followup',
               'end_of_study_date')



# we make sure all values within the date columns are in date format:
full_df[date_cols] <- lapply(full_df[date_cols], as.Date)

# we create the end_of_fu column by only keeping the earliest date from each rows
# within each date columns:
full_df$end_of_fu <- apply(full_df[date_cols], 1, function(x) min(x[!is.na(x)]))

#print(full_df$end_of_fu)
```

### Follow-up time 
We can now create the "follow-up time" column by calculating the difference (in months) 
between the "end of follow up" and "end time of wear" columns:
```{r}
# remove NA data from date_end_accel (to do in data exclusion UKBB script?)
full_df <- full_df[!is.na(full_df$date_end_accel), ]

difftime_weeks <- difftime(full_df$end_of_fu, full_df$date_end_accel, units = "weeks")

# because the "difftime" function only allows a maximum of units in weeks, we 
# devide by 4.345 to convert to difference months
full_df$fu_time <- as.numeric(difftime_weeks) / 4.345

head(full_df$fu_time) 
#print(full_df$date_start_accel)

hist(full_df$fu_time, main = "survival time in Month")



```


### CVD indicator (strokes and MI)

```{r}
# First we create a new column which will indicate if a participant has had: 
## a) a stroke == 1; or not == 0:
stroke_cols <- c('stroke_date', 'ischaemic_stroke_date', 'intracerebral_haemorrhage_date')

# Create the 'stroke' column
full_df$stroke <- ifelse(rowSums(!is.na(full_df[, stroke_cols ])) > 0, 1, 0)


## b) a MI == 1; or not == 0:
MI_cols <- c('myocardial_infarction_date', 'STEMI_date', 'NSTEMI_date')
full_df$MI <- ifelse(rowSums(!is.na(full_df[, MI_cols ])) > 0, 1, 0)


head(full_df$stroke)
head(full_df$MI)

# We now create a composit "CVD" column which indicates if the participants has had a
# stroke and/or MI (==1) or not (==0)
full_df <- full_df %>%
  mutate(CVD = ifelse(stroke == 1 | MI == 1, 1, 0))
```







## PA 
### Now link data with acclerometer weekly minutes, for LPA, MVPA, and sedendary behavior.   
- There are 3 diferent accelerometric measures   
  1. PA1 - Vector magnitude based measures as calcuated from time-series of vector magnitude by UKBB 
  2. PA2 - machine-learning derived mesared, for Field ID 1020
  3. PA3 (pending) - Actigraph count-based measure, based on Freedson cutoff 


### PA2 Load derived accelerometer from UKBB, PA2 data 
```{r, include=FALSE}
ML_derived_PA2 <- fread("/home/yacine/survival_analysis/PA2_category_1020.csv")
ML_derived_PA2 <- ML_derived_PA2 %>%  dplyr::select(
  eid, 
  "40048-0.0",  
  "40049-0.0",
  "40047-0.0", 
  "40046-0.0", 
  "40044-0.0",  
  "40045-0.0",
  "40043-0.0", 
  "40042-0.0" 
)

# relabel for id, weekly light PA, weekly MVPA, weekly sleep, weekly sedentary, daily light PA, daily MVPA, daily sedentary
names(ML_derived_PA2) <- c("eid", "overall_l", "overall_mv", "overall_sb", "overall_slp", "day_l", "day_mv", "day_sb", "day_slp")

ML_derived_PA2 <- ML_derived_PA2 %>% filter(!is.na(overall_l))

dim(ML_derived_PA2)


ML_derived_PA2$MVPA_min <- ML_derived_PA2$overall_mv * 7 * 24 * 60 



ML_derived_PA2$MVPA_min <- ML_derived_PA2$overall_mv* 7*24*60
ML_derived_PA2$LPA_min <- ML_derived_PA2$overall_l* 7*24*60
ML_derived_PA2$SB_min <- ML_derived_PA2$overall_sb* 7*24*60

colnames(ML_derived_PA2) <- paste(colnames(ML_derived_PA2), "_PA2", sep = "")
colnames(ML_derived_PA2)[1] <- "eid"


```




### PA1 Files from parallel processing of time-series (FieldID 90004) to generate ENMO summary of 100,000 ppl, PA1 data 
```{r, include=FALSE, message=FALSE}
enmoTSParallel_PA1 <- list.files(path="/home/yacine/survival_analysis/PA1_parallel_TS_ENMO/outputs", full.names = TRUE) %>% 
  lapply(read_csv) %>% 
  bind_rows 

enmoTSParallel_PA1$MVPA_min <- enmoTSParallel_PA1$MVPA_total* 7*24*60
enmoTSParallel_PA1$LPA_min <- enmoTSParallel_PA1$LPA_total* 7*24*60
enmoTSParallel_PA1$SB_min <- enmoTSParallel_PA1$SB_total* 7*24*60

colnames(enmoTSParallel_PA1) <- paste(colnames(enmoTSParallel_PA1), "_PA1", sep = "")
colnames(enmoTSParallel_PA1)[1] <- "eid"




```



### Merge the full_df and PA1 and PA2 df by eids
```{r}
full_df_PA <- inner_join(
  full_df, 
  enmoTSParallel_PA1 %>% 
    dplyr::select(eid, MVPA_min_PA1, LPA_min_PA1, SB_min_PA1),
  by = "eid")

full_df_PA<- inner_join(full_df_PA, 
  ML_derived_PA2 %>% 
    dplyr::select(eid, MVPA_min_PA2, LPA_min_PA2, SB_min_PA2),
  by = "eid")

```




### Cretea quantile pA group...
```{r}
sum(full_df_PA$MVPA_min_PA1 > 2500 )
summary(full_df_PA$MVPA_min_PA1)

sum(full_df_PA$MVPA_min_PA2 > 2500 )
summary(full_df_PA$MVPA_min_PA2)


dim(full_df_PA)
full_df_PA <- full_df_PA %>%  filter(MVPA_min_PA2 < 2500)
full_df_PA <- full_df_PA %>%  filter(MVPA_min_PA1 < 2500)
dim(full_df_PA)


full_df_PA$MVPA_Quant_PA1 <- dvmisc::quant_groups(full_df_PA$MVPA_min_PA1, 4) %>% factor()
full_df_PA$MVPA_Quant_PA2 <- dvmisc::quant_groups(full_df_PA$MVPA_min_PA2, 4) %>% factor()


dfPA1Label <- data.frame(range = full_df_PA$MVPA_Quant_PA1 %>% levels(), Q = c("Q1", "Q2", "Q3", "Q4"))
dfPA2Label <- data.frame(range = full_df_PA$MVPA_Quant_PA2 %>% levels(), Q = c("Q1", "Q2", "Q3", "Q4"))

```



### Plot MVPA 
```{r}
# check plot to see if there are extreme data points or not 
boxplot(MVPA_min_PA1 ~ MVPA_Quant_PA1, data = full_df_PA, main = "Categorical MVPA CV Numeric MVPA")
boxplot(MVPA_min_PA2 ~ MVPA_Quant_PA2, data = full_df_PA, main = "Categorical MVPA CV Numeric MVPA")



# And scatter plot 
library(ggExtra)
library(BlandAltmanLeh)
print(ggExtra::ggMarginal(
  bland.altman.plot(
    full_df_PA$MVPA_min_PA1, 
    full_df_PA$MVPA_min_PA2, 
    graph.sys = "ggplot2"
    ),
  theme_minimal(),
  type = "histogram", size=4)
)



ggplot(full_df_PA, 
       aes(x=full_df_PA$MVPA_min_PA1, 
           y=full_df_PA$MVPA_min_PA2)) + 
  geom_point(color="black", size = 0.3) +
  theme_classic() + 
  xlab("MVPA minues / week - ENMO") + 
  ylab("MVPA minues / week - ML") +  
  geom_smooth(method=lm, 
    se=FALSE, 
    linetype="dashed",
    color="grey"
  )




```



### Excess duration - Flag people with too high values of MVPA and make new category removing them 
```{r}
full_df_PA <- full_df_PA %>%  
  mutate( MVPA_min_PA1_truncated = ifelse(MVPA_min_PA1 > 1250, NA, MVPA_min_PA1), 
          MVPA_min_PA2_truncated = ifelse(MVPA_min_PA2 > 1250, NA, MVPA_min_PA2)) 


full_df_PA$MVPA_Quant_PA1_trucated <- dvmisc::quant_groups(full_df_PA$MVPA_min_PA1_truncated, 4) %>% factor()
full_df_PA$MVPA_Quant_PA2_trucated <- dvmisc::quant_groups(full_df_PA$MVPA_min_PA2_truncated, 4) %>% factor()


dfPA1LabelTrunc <- data.frame(range = full_df_PA$MVPA_Quant_PA1_trucated %>% levels(), Q = c("Q1", "Q2", "Q3", "Q4"))
dfPA2LabelTrunc <- data.frame(range = full_df_PA$MVPA_Quant_PA2_trucated %>% levels(), Q = c("Q1", "Q2", "Q3", "Q4"))
```


## Covariates - reorder 
```{r}
# Re-order categories 
full_df_PA$cooked_vg %>% table
full_df_PA$cooked_vg <- factor(full_df_PA$cooked_vg)
levels(full_df_PA$cooked_vg)
levels(full_df_PA$cooked_vg) <- list( 'Less than 2 servings a day' ="< 2 servings/day", 'Between 2 and 4 servings a day' = "2 to 4 servings/day", 'More than 4 servings a day' =  "More than 4 servings/day") 
full_df_PA$cooked_vg %>% table


full_df_PA$fresh_fruit %>% table
full_df_PA$fresh_fruit <- factor(full_df_PA$fresh_fruit)
levels(full_df_PA$fresh_fruit)
levels(full_df_PA$fresh_fruit) <- list( 'Less than 2 servings a day' ="< 2 servings/day", 'Between 2 and 4 servings a day' = "2 to 4 servings/day", 'More than 4 servings a day' =  "More than 4 servings/day") 
full_df_PA$fresh_fruit %>% table


full_df_PA$smoking %>% table 
full_df_PA$smoking<- factor(full_df_PA$smoking)
levels(full_df_PA$smoking)
levels(full_df_PA$smoking) <- list( 'Never' = "Never", 
                                    'Previous' = "Previous", 
                                    'Current' =  "Current") 


full_df_PA$BMI %>% table 
full_df_PA$BMI <- factor(full_df_PA$BMI)
levels(full_df_PA$BMI)
levels(full_df_PA$BMI) <- list( "Underweight (< 18.5 kg/m2)" = "Underweight (< 18.5 kg/m2)",
                                "Normal (18.5 kg/m2 to < 25 kg/m2)" = "Normal (18.5 kg/m2 to < 25 kg/m2)" ,
                                "Overweight (25 kg/m2 to < 30 kg/m2)" = "Overweight (25 kg/m2 to < 30 kg/m2)",
                                "Obesity Class I, II or III (> 30 kg/m2)" = "Obesity Class I, II or III (> 30 kg/m2)") 

full_df_PA$alcohol %>% table 
full_df_PA$alcohol <- factor(full_df_PA$alcohol)
levels(full_df_PA$alcohol)
levels(full_df_PA$alcohol) <- list( "Never" = "Never", 
                                    "Less than once a week" = "Less than once a week", 
                                    "Once or twice a week" =  "Once or twice a week",
                                    "Three or four times a week" = "Three or four times a week",
                                    "Daily or almost daily" = "Daily or almost daily") 


full_df_PA$avg_hh_income %>% table 
full_df_PA$avg_hh_income <- factor(full_df_PA$avg_hh_income)
levels(full_df_PA$avg_hh_income)
levels(full_df_PA$avg_hh_income) <- list( "Less than 18,000" = "Less than 18,000",
                                          "18,000 to 30,999" = "18,000 to 30,999",
                                          "31,000 to 51,999" = "31,000 to 51,999",
                                          "52,000 to 100,000" = "52,000 to 100,000",
                                          "Greater than 100,000" = "Greater than 100,000",
                                          "Do not know/Prefer not to answer" = "Do not know/Prefer not to answer") 


full_df_PA$processed_meat %>% table 
full_df_PA$processed_meat <- factor(full_df_PA$processed_meat)
levels(full_df_PA$processed_meat)
levels(full_df_PA$processed_meat) <- list( "Less than 2 times a week" = "Less than 2 times a week", 
                                    "2-4 times a week" = "2-4 times a week", 
                                    "More than 4 times a week" =  "More than 4 times a week") 

full_df_PA$oily_fish %>% table 
full_df_PA$oily_fish <- factor(full_df_PA$oily_fish)
levels(full_df_PA$oily_fish)
levels(full_df_PA$oily_fish) <- list( "Less than 2 times a week" = "Less than 2 times a week", 
                                    "2-4 times a week" = "2-4 times a week", 
                                    "More than 4 times a week" =  "More than 4 times a week") 

full_df_PA$non_oily_fish %>% table 
full_df_PA$non_oily_fish <- factor(full_df_PA$non_oily_fish)
levels(full_df_PA$non_oily_fish)
levels(full_df_PA$non_oily_fish) <- list( "Less than 2 times a week" = "Less than 2 times a week", 
                                    "2-4 times a week" = "2-4 times a week", 
                                    "More than 4 times a week" =  "More than 4 times a week") 

full_df_PA$red_meat %>% table 
full_df_PA$red_meat <- factor(full_df_PA$red_meat)
levels(full_df_PA$red_meat)
levels(full_df_PA$red_meat) <- list( "Less than 2 times a week" = "Less than 2 times a week", 
                                    "2-4 times a week" = "2-4 times a week", 
                                    "More than 4 times a week" =  "More than 4 times a week") 

full_df_PA$education_level %>% table 
full_df_PA$education_level <- factor(full_df_PA$education_level)
levels(full_df_PA$education_level)
levels(full_df_PA$education_level) <- list( "None of the above" = "None of the above", 
                                    "O levels/GCSEs or equivalent, CSEs or equivalent" =  "O levels/GCSEs or equivalent, CSEs or equivalent",
                                    "A levels/AS, NVQ/HND/HNC or equivalent" = "A levels/AS, NVQ/HND/HNC or equivalent",
                                    "College or University degree" = "College or University degree") 

```



## Table 1
```{r}
# Variables to add to the table - this variable cannot be used to select colum,ns now, since cooked_veg is not rendred into summary table 


# Obesity category names can be shortened 
# Note that all vars , except alcohol, do not know and unkjnan shoudl be meet with exclusion 
dt <- full_df_PA %>%  dplyr::select(
  fu_time, 
  MVPA_Quant_PA2,  
  MVPA_Quant_PA1,  
  MVPA_min_PA1, 
  MVPA_min_PA2, 
  MI, 
  stroke,
  age_entry_years, 
  ethnicity, 
  sex, 
  education_level,
  avg_hh_income,
  tdi_quarters,
  avg_hh_income,
  BMI,
  diabetes, 
  smoking, 
  alcohol, 
  processed_meat, 
  red_meat,
  oily_fish,
  non_oily_fish,
  fresh_fruit,
  cooked_vg, 
  MVPA_Quant_PA1_trucated, 
  MVPA_Quant_PA2_trucated
  )



# Convert varaible names into deescriptive tabl enames 
varNameDf <- data.frame(
  varName = c("Myocardial Infarction",
              "Stroke",
              "Age",
              "MVPA min/week",
              "Race", 
              "Type II Diabetes", 
              "Deprivation index", 
              "Education", 
              "Household Income",
              "Smoking", 
              "Alcohol", 
              "Processed meat",
              "Red meat",
              "Fresh fruit", 
              "Cooked vegetables", 
              "Oily fish", 
              "Non-oily fish",
              "Sex", 
              "Follow_up time", 
              "Body Mass Index"
  ), 
  ChartName = c("MI", 
              "stroke",
              "age_entry_years",
              "MVPA_min_PA1", 
              "ethnicity", 
              "diabetes", 
              "tdi_quarters", 
              "education_level", 
              "avg_hh_income",
              "smoking", 
              "alcohol", 
              "processed_meat", 
              "red_meat",
              "fresh_fruit", 
              "cooked_vg", 
              "oily_fish", 
              "non_oily_fish",
              "sex", 
              "fu_time", 
              "BMI")
)


var_names <- varNameDf %>% 
    select(varName, ChartName) %>% 
    tibble::deframe()

dt <- dt %>% 
    rename(!!!var_names)


tb <- dt %>% 
  dplyr::select(-contains("trucated")) %>% 
  dplyr::select( -MVPA_Quant_PA1) %>% 
  tbl_summary(
    by = MVPA_Quant_PA2,  
    #statistic = all_continuous() ~ "{mean} ({sd})"
    #digits = all_continuous() ~ 1,
  ) %>% 
  as_flex_table()



# Landscape (word format)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "landscape",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )


print(tb)

# Save 
flextable::save_as_docx("Distribution of participant characteristics by Qurtile of Moderate_Vigorous Physical Activity" = tb,  
               path = "testTable.docx", 
               pr_section = sect_properties
               )  
```


```{r}
#pairs(inl)

library(ggcorrplot)
model.matrix(~0+., data=dt) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag=FALSE, type="lower", lab=F, lab_size=2)




```





  
  
## Regression - Associations with risk of incident cardiovascular disease 

In the data preparation step, we added an event status indicator at exit and a follow-up time variable. Using these, we can run a Cox model to associate overall activity with risk of incident cardiovascular disease. We'll start by using time-on-study as the timescale and set it up using the 'survival' package in R. We'll also adjust for various possible confounding variables (following the confounders used by [Ramakrishnan et al.](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1003487)):


First , create formula 
```{r}

f_cov <- "Sex + Age + Race + `Deprivation index` + Education + `Household Income` + Smoking + Alcohol + `Processed meat` + `Fresh fruit` + `Cooked vegetables` + `Oily fish` + `Non-oily fish` + `Type II Diabetes` + `Body Mass Index`"

f_cov_noMediator <- "Sex + Age + Race + `Deprivation index` + Education + `Household Income` + Smoking + Alcohol + `Processed meat` + `Fresh fruit` + `Cooked vegetables` + `Oily fish` + `Non-oily fish`"

f_stroke <-   "Surv(`Follow_up time`,`Myocardial Infarction`)"

f_MI <- "Surv(`Follow_up time`,`Stroke`)"


#as.formula(paste("Surv(`Follow_up time`,`Myocardial Infarction`) ~ ", "MVPA_Quant_PA2 + ",  f_cov))  
#as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA2 + ",  f_cov))



```


### Stroke - Main 
```{r}

# Model for PA 1 
fitDf1 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA1 + ",  f_cov)), data = dt)
tb1<- tbl_regression(fitDf1, exponentiate = TRUE, 
                     label = list("MVPA_Quant_PA1" = "MVPA Quartile"))


fitDf2 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA2 + ",  f_cov)), data = dt)
tb2<- tbl_regression(fitDf2, exponentiate = TRUE, 
                     label = list("MVPA_Quant_PA2" = "MVPA Quartile"))




#Merge tables 
tb3 <- tbl_merge(
  tbls = list(tb1, tb2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")) %>% 
  bold_labels() %>% 
   modify_column_hide(columns = c(p.value_1, p.value_2))


# Landscape (word format)
tb3 <- as_flex_table(tb3)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "portrait",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Hazard ratios for icidence Myocardial Infarction" = tb3,  
  path = "HR_main_MI.docx", 
  pr_section = sect_properties
)  


```
  
  
  
  
### MI - Main 
```{r}

# Model for PA 1 
fitDf1 <- coxph(as.formula(paste(f_MI, " ~" ,  "MVPA_Quant_PA1 + ",  f_cov)), data = dt)
tb1<- tbl_regression(fitDf1, exponentiate = TRUE, label = list("MVPA_Quant_PA1" = "MVPA Quartile"))


#Model for PA 2 
fitDf2 <- coxph(as.formula(paste(f_MI, " ~" ,  "MVPA_Quant_PA2 + ",  f_cov)), data = dt)
tb2<- tbl_regression(fitDf2, exponentiate = TRUE, label = list("MVPA_Quant_PA2" = "MVPA Quartile"))

tb3 <- tbl_merge(
  tbls = list(tb1, tb2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")) %>% 
  bold_labels() %>% 
  modify_column_hide(columns = c(p.value_1, p.value_2))


# Landscape (word format)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "portrait",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Hazard ratios for icidence stroke" = tb3,  
  path = "HR_main_Stroke.docx", 
  pr_section = sect_properties
)  

```







# Sensitivity anlaysis  
### sensitivity - no Mediator , withoubt BMI and Diabetes , Stroke 
See covarite set - no mediator (BMI  and diabetes)
```{r}
# Model for PA 1 
fit1 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA1 + ",  f_cov_noMediator)), data = dt)
t1<- tbl_regression(fit1, exponentiate = TRUE, 
                    label = list("MVPA_Quant_PA1" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA1"
                    )# %>%  
  #modify_table_body(
  #  ~.x %>% 
  #    mutate(
  #      label  = ifelse(label ==  dfPA1Label[1, "range"], "Q1",label),
  #      label  = ifelse(label ==  dfPA1Label[2, "range"], "Q2",label),
  #      label  = ifelse(label ==  dfPA1Label[3, "range"], "Q3",label),
  #      label  = ifelse(label ==  dfPA1Label[4, "range"], "Q4",label)
  #           )) 

fit2 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA2 + ",  f_cov_noMediator)), data = dt)
t2<- tbl_regression(fit2, exponentiate = TRUE,  
                    label = list("MVPA_Quant_PA2" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA2"
                    )  #%>%  
  #modify_table_body(
  #  ~.x %>% 
  #    mutate(
  #      label  = ifelse(label ==  dfPA2Label[1, "range"], "Q1",label),
  #      label  = ifelse(label ==  dfPA2Label[2, "range"], "Q2",label),
  #      label  = ifelse(label ==  dfPA2Label[3, "range"], "Q3",label),
  #      label  = ifelse(label ==  dfPA2Label[4, "range"], "Q4",label)
  #           ))

#Merge tables 
t3 <- tbl_merge(
  tbls = list(t1, t2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")
) %>%  bold_labels() %>% 
   modify_column_hide(columns = c(p.value_1, p.value_2))

# Landscape (word format)
t3 <- as_flex_table(t3)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "portrait",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Without BMI and Diabetes" = t3,  
  path = "HR_Sens_Diabetes_Stroke.docx", 
  pr_section = sect_properties
)  
```
### sensitivity - no Mediator , withoubt BMI and Diabetes , MI
```{r}
# Model for PA 1 
fit1 <- coxph(as.formula(paste(f_MI, " ~" ,  "MVPA_Quant_PA1 + ",  f_cov_noMediator)), data = dt)
t1<- tbl_regression(fit1, exponentiate = TRUE, 
                    label = list("MVPA_Quant_PA1" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA1"
                    )

fit2 <- coxph(as.formula(paste(f_MI, " ~" ,  "MVPA_Quant_PA2 + ",  f_cov_noMediator)), data = dt)
t2<- tbl_regression(fit2, exponentiate = TRUE,  
                    label = list("MVPA_Quant_PA2" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA2"
                    )  

t3 <- tbl_merge(
  tbls = list(t1, t2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")
) %>%  bold_labels() %>% 
   modify_column_hide(columns = c(p.value_1, p.value_2))

# Landscape (word format)
t3 <- as_flex_table(t3)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "portrait",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Without BMI and Diabetes" = t3,  
  path = "HR_Sens_Diabetes_MI.docx", 
  pr_section = sect_properties
)  
```






### sensitivity2 - Removed people with huge duration (>1200min) of MVPA Stroke 
```{r}

# Model for PA 1 
fit1 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA1_trucated + ",  f_cov)), data = dt)
t1<- tbl_regression(fit1, exponentiate = TRUE, 
                    label = list("MVPA_Quant_PA1_trucated" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA1_trucated"
                    ) 

fit2 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA2_trucated + ",  f_cov)), data = dt)
t2<- tbl_regression(fit2, exponentiate = TRUE,  
                    label = list("MVPA_Quant_PA2_trucated" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA2_trucated"
                    )  

#Merge tables 
t3 <- tbl_merge(
  tbls = list(t1, t2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")
)

# Landscape (word format)
t3 <- as_flex_table(t3)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "portrait",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Hazard ratios for icidence stroke, truncated MVPA" = t3,  
  path = "HR_Sens_truncated_Stroke.docx", 
  pr_section = sect_properties
)  

```




### sensitivity2 - Removed people with huge duration (>1200min) of MVPA, MI 
```{r}

# Model for PA 1 
fit1 <- coxph(as.formula(paste(f_MI, " ~" ,  "MVPA_Quant_PA1_trucated + ",  f_cov)), data = dt)
t1<- tbl_regression(fit1, exponentiate = TRUE, 
                    label = list("MVPA_Quant_PA1_trucated" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA1_trucated"
                    ) 

fit2 <- coxph(as.formula(paste(MI, " ~" ,  "MVPA_Quant_PA2_trucated + ",  f_cov)), data = dt)
t2<- tbl_regression(fit2, exponentiate = TRUE,  
                    label = list("MVPA_Quant_PA2_trucated" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA2_trucated"
                    )  

#Merge tables 
t3 <- tbl_merge(
  tbls = list(t1, t2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")
)

# Landscape (word format)
t3 <- as_flex_table(t3)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "portrait",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Hazard ratios for icidence MI, truncated MVPA" = t3,  
  path = "HR_Sens_truncated_MI.docx", 
  pr_section = sect_properties
)  

```

### Sensitivity 3 - Male and Female separate 
See the data soruce in the regression command
Female 
```{r}

# Model for PA 1 
fit1 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA1_trucated + ",  gsub(x = f_cov, pattern = "Sex \\+", replacement = ""))), data = dt[dt$Sex == "Female", ])
t1<- tbl_regression(fit1, exponentiate = TRUE, 
                    label = list("MVPA_Quant_PA1_trucated" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA1_trucated"
                    ) 

fit2 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA2_trucated + ",  gsub(x = f_cov, pattern = "Sex \\+", replacement = ""))), data = dt[dt$Sex == "Female", ])
t2<- tbl_regression(fit2, exponentiate = TRUE,  
                    label = list("MVPA_Quant_PA2_trucated" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA2_trucated"
                    )  

#Merge tables 
t3 <- tbl_merge(
  tbls = list(t1, t2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")
)

# Landscape (word format)
t3 <- as_flex_table(t3)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "portrait",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Female - azard ratios for icidence stroke" = t3,  
  path = "HR_Sens_Female_stroke.docx", 
  pr_section = sect_properties
)  


```


```{r}

# Model for PA 1 
fit1 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA1_trucated + ",  gsub(x = f_cov, pattern = "Sex \\+", replacement = ""))), data = dt[dt$Sex == "Male", ])
t1<- tbl_regression(fit1, exponentiate = TRUE, 
                    label = list("MVPA_Quant_PA1_trucated" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA1_trucated"
                    ) 

fit2 <- coxph(as.formula(paste(f_stroke, " ~" ,  "MVPA_Quant_PA2_trucated + ",  gsub(x = f_cov, pattern = "Sex \\+", replacement = ""))), data = dt[dt$Sex == "Male", ])
t2<- tbl_regression(fit2, exponentiate = TRUE,  
                    label = list("MVPA_Quant_PA2_trucated" = "MVPA Quartile"), 
                    include = "MVPA_Quant_PA2_trucated"
                    )  

#Merge tables 
t3 <- tbl_merge(
  tbls = list(t1, t2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")
)

# Landscape (word format)
t3 <- as_flex_table(t3)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "portrait",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Male - azard ratios for icidence stroke" = t3,  
  path = "HR_Sens_Male_stroke.docx", 
  pr_section = sect_properties
)  


```










### Sensitivity 4 - 2 years of survival 






##########
Kaplan_Meier:
  - 2 groups: PA1 and PA2 or Stroke and MI?
  - d_stroke == 1; d_MI == 1
  - end_of_fu = censoring time
  
```{r}
  
kmfit1_mi <- survfit(Surv(`Follow_up time`, `Myocardial Infarction`) ~ `MVPA_Quant_PA1`, data = dt)
kmfit1_stroke <- survfit(Surv(`Follow_up time`, `Stroke`) ~ `MVPA_Quant_PA1`, data = dt)


kmfit2_mi <- survfit(Surv(`Follow_up time`, `Myocardial Infarction`) ~ `MVPA_Quant_PA2`, data = dt)
kmfit2_stroke <- survfit(Surv(`Follow_up time`, `Stroke`) ~ `MVPA_Quant_PA2`, data = dt)


```



```{r}

plot(kmfit1_mi, col = c("black", "grey", "blue", "red"), xlab = "Survival time per month", ylab = "Survival Probabilities", ylim = c(1.0, 0.95))
legend("bottomleft", c("[0.167,319]", "(319,464]", "(464,641]", "(641,2.39e+03]"), 
       col = c("black", "grey", "blue", "red"), lty = 1)
title(main = "MI - PA1 by Quarters")

plot(kmfit1_stroke, col = c("black", "grey", "blue", "red"), xlab = "Survival time per month", ylab = "Survival Probabilities", ylim = c(1.0, 0.95))
legend("bottomleft", c("[0.167,319]", "(319,464]", "(464,641]", "(641,2.39e+03]"), 
       col = c("black", "grey", "blue", "red"), lty = 1)
title(main = "Stroke - PA1 by Quarters")


plot(kmfit2_mi, col = c("black", "grey", "blue", "red"), xlab = "Survival time per month", ylab = "Survival Probabilities", ylim = c(1.0, 0.95))
legend("bottomleft", c("[0.167,319]", "(319,464]", "(464,641]", "(641,2.39e+03]"),
       col = c("black", "grey", "blue", "red"), lty = 1)
title(main = "MI - PA2 by Quarters")


plot(kmfit2_stroke, col = c("black", "grey", "blue", "red"), xlab = "Survival time per month", ylab = "Survival Probabilities", ylim = c(1.0, 0.95))
legend("bottomleft", c("[0.167,319]", "(319,464]", "(464,641]", "(641,2.39e+03]"), 
       col = c("black", "grey", "blue", "red"), lty = 1)
title(main = "Stroke - PA2 by Quarters")

```


```{r}

par(mfrow = c(2, 2), oma = c(0, 0, 2, 0)) 

# ENMO MI
plot(kmfit1_mi, col = c("black", "grey", "blue", "red"), 
     xlab = "Survival time per month", 
     ylab = "Survival Probabilities", 
     ylim = c(1.0, 0.95))
legend("bottomleft", c("[0.167,319]", "(319,464]", "(464,641]", "(641,2.39e+03]"), cex=0.5,
       col = c("black", "grey", "blue", "red"), lty = 1)
title(main = "MI - ENMO by Quarters")

# ENMO Stroke
plot(kmfit1_stroke, col = c("black", "grey", "blue", "red"), 
     xlab = "Survival time per month", 
     ylab = "Survival Probabilities", 
     ylim = c(1.0, 0.95))
legend("bottomleft", c("[0.167,319]", "(319,464]", "(464,641]", "(641,2.39e+03]"), cex=0.5, 
       col = c("black", "grey", "blue", "red"), lty = 1)
title(main = "Stroke - ENMO by Quarters")

# ML MI
plot(kmfit2_mi, col = c("black", "grey", "blue", "red"), 
     xlab = "Survival time per month", 
     ylab = "Survival Probabilities", 
     ylim = c(1.0, 0.95))
legend("bottomleft", c("[0.167,319]", "(319,464]", "(464,641]", "(641,2.39e+03]"), cex=0.5, 
       col = c("black", "grey", "blue", "red"), lty = 1)
title(main = "MI - ML by Quarters")

# ML Stroke
plot(kmfit2_stroke, col = c("black", "grey", "blue", "red"), 
     xlab = "Survival time per month", 
     ylab = "Survival Probabilities", 
     ylim = c(1.0, 0.95))
legend("bottomleft", c("[0.167,319]", "(319,464]", "(464,641]", "(641,2.39e+03]"), cex=0.5, 
       col = c("black", "grey", "blue", "red"), lty = 1)
title(main = "Stroke - ML by Quarters")


mtext("KM Curves by Quartiles", outer = TRUE, cex = 1.5) # main title
#legend("bottomleft", legend = c("Q1", "Q2", "Q3", "Q4"), 
       #col = c("black", "grey", "blue", "red"), lty = 1, cex = 0.8) # legend for one graph only
#mtext("Survival time per month", side = 1, outer = TRUE, line = 2.5) # y-axis title for full figure
#mtext("Survival Probabilities", side = 2, outer = TRUE, line = 2.5) # x-axis title for full figure
```






Log-log tentative: 

```{r}


# we create a function to transform the KM model to Log-log function:
log_log_transform <- function(surv_fit) {
  surv_summary <- summary(surv_fit)
  data.frame(
    time = surv_summary$time,
    log_log_surv = log(-log(surv_summary$surv)),
    strata = surv_summary$strata
  )
}

log_log_kmfit1_mi <- log_log_transform(kmfit1_mi)
log_log_kmfit1_stroke <- log_log_transform(kmfit1_stroke)
log_log_kmfit2_mi <- log_log_transform(kmfit2_mi)
log_log_kmfit2_stroke <- log_log_transform(kmfit2_stroke)


# we create a function to create Log-log function plots
plot_log_log_survival <- function(log_log_data, title) {
  ggplot(log_log_data, aes(x = time, y = log_log_surv, color = strata)) +
    geom_step() +
    labs(title = title, x = "Time in Month", y = "Log-log Survival") +
    #xlim(c(0, NA)) + # start x-axis at time == 0
    theme_minimal()
}

plot1_mi <- plot_log_log_survival(log_log_kmfit1_mi, "Log-Log Survival Curve for MI per ENMO Quarters Comparison")
plot1_stroke <- plot_log_log_survival(log_log_kmfit1_stroke, "Log-Log Survival Curve for Stroke per ENMO Quarters Comparison")
plot2_mi <- plot_log_log_survival(log_log_kmfit2_mi, "Log-Log Survival Curve for MI per ML Quarters Comparison")
plot2_stroke <- plot_log_log_survival(log_log_kmfit2_stroke, "Log-Log Survival Curve for Stroke per ML Quarters Comparison")


print(plot1_mi)
print(plot1_stroke)
print(plot2_mi)
print(plot2_stroke)


```


Schoenfeld residuals: 

```{r}
library(survminer)

# we test the proportional hazards assumption of a Cox regression model:

test_ph1 <- cox.zph(fitDf1)
test_ph2 <- cox.zph(fitDf2)


# we plot the Schoenfeld residuals graphs using the Cox regression model: 

ggcoxzph(test_ph1, var = 'MVPA_Quant_PA1')
ggcoxzph(test_ph2, var = 'MVPA_Quant_PA2')



#?ggcoxzph


```




