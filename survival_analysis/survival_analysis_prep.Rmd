---
title: "survival_analysis_prep"
author: "yacine"
date: "2024-07-16"
output:
  pdf_document: default
  html_document: default
---

We load and/or install the packages we will be using:

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Refresh environment 
rm(list= ls())
library(dplyr)
library(survival)
library(data.table)
library(readr)
library(dvmisc)
library(gtsummary)
library(gt)
library(kableExtra)
#remotes::install_github("larmarange/broom.helpers")
library(broom.helpers)
library(flextable)
library(officer)

```

We load the data:
```{r}
#full_df <- read.csv("/home/yacine/final_df_full.csv") # full df w/o exclusions
#full_df <- read.csv("/home/yacine/UKBB_beluga/df_exc.csv") # full df with exclusions
full_df <- read.csv("/home/yacine/UKBB_beluga/df_exc_recode.csv") # full df with exclusions + recoding
```

We change the date format for the start and end accelerometer variables - which
will be crucial for later steps:
```{r}
full_df$date_start_accel <- as.Date(full_df$date_start_accel)
full_df$date_end_accel <- as.Date(full_df$date_end_accel)
```


## Follow-up time:

First we create the "end_of_fu" variable, which can be classified as date of 
stroke/MI, date of death or the end of the study (i.e. 2022):

```{r}
# we find out which death date is the latest which we will set as the "end of the study" 
# date
max_death_date_0 <- max(full_df$'date_of_death_0', na.rm = TRUE)
max_death_date_1 <- max(full_df$'date_of_death_1', na.rm = TRUE)
print(max_death_date_0)
print(max_death_date_1)

# given that we see that the max(death_date) is "2022-12-17", this will serve as 
# our "end of study" date

# we create a "end_of_study" column which indicates the end of the whole data collection:
full_df$end_of_study_date <- as.Date('2022-12-17')

# we reate a vector of all the date columns:
date_cols <- c('stroke_date', 'ischaemic_stroke_date', 'intracerebral_haemorrhage_date',
               'myocardial_infarction_date', 'STEMI_date', 'NSTEMI_date',
               'date_of_death_0', 'date_of_death_1', 'date_lost_followup',
               'end_of_study_date')



# we make sure all values within the date columns are in date format:
full_df[date_cols] <- lapply(full_df[date_cols], as.Date)

# we create the end_of_fu column by only keeping the earliest date from each rows
# within each date columns:
full_df$end_of_fu <- apply(full_df[date_cols], 1, function(x) min(x[!is.na(x)]))

#print(full_df$end_of_fu)
```

We can now create the "follow-up time" column by calculating the difference (in months) 
between the "end of follow up" and "end time of wear" columns:
```{r}
# remove NA data from date_end_accel (to do in data exclusion UKBB script?)
full_df <- full_df[!is.na(full_df$date_end_accel), ]

difftime_weeks <- difftime(full_df$end_of_fu, full_df$date_end_accel, units = "weeks")

# because the "difftime" function only allows a maximum of units in weeks, we 
# devide by 4.345 to convert to difference months
full_df$fu_time <- as.numeric(difftime_weeks) / 4.345

head(full_df$fu_time) 
#print(full_df$date_start_accel)

hist(full_df$fu_time, main = "survival time in Month")
```


##### Create binary variable for CVD (strokes and MI)

```{r}
# First we create a new column which will indicate if a participant has had: 
## a) a stroke == 1; or not == 0:
stroke_cols <- c('stroke_date', 'ischaemic_stroke_date', 'intracerebral_haemorrhage_date')

# Create the 'stroke' column
full_df$stroke <- ifelse(rowSums(!is.na(full_df[, stroke_cols ])) > 0, 1, 0)


## b) a MI == 1; or not == 0:
MI_cols <- c('myocardial_infarction_date', 'STEMI_date', 'NSTEMI_date')
full_df$MI <- ifelse(rowSums(!is.na(full_df[, MI_cols ])) > 0, 1, 0)


head(full_df$stroke)
head(full_df$MI)

# We now create a composit "CVD" column which indicates if the participants has had a
# stroke and/or MI (==1) or not (==0)
full_df <- full_df %>%
  mutate(CVD = ifelse(stroke == 1 | MI == 1, 1, 0))
```






################ GitHub PA code

# Now link data with acclerometer weekly minutes, for LPA, MVPA, and sedendary behavior.   
- There are 3 diferent accelerometric measures   
  1. PA1 - Vector magnitude based measures as calcuated from time-series of vector magnitude by UKBB 
  2. PA2 - machine-learning derived mesared, for Field ID 1020
  3. PA3 (pending) - Actigraph count-based measure, based on Freedson cutoff 


#Load derived accelerometer from UKBB, PA2 data 
```{r, include=FALSE}
ML_derived_PA2 <- fread("/home/yacine/survival_analysis/PA2_category_1020.csv")
ML_derived_PA2 <- ML_derived_PA2 %>%  dplyr::select(
  eid, 
  "40048-0.0",  
  "40049-0.0",
  "40047-0.0", 
  "40046-0.0", 
  "40044-0.0",  
  "40045-0.0",
  "40043-0.0", 
  "40042-0.0" 
)

# relabel for id, weekly light PA, weekly MVPA, weekly sleep, weekly sedentary, daily light PA, daily MVPA, daily sedentary
names(ML_derived_PA2) <- c("eid", "overall_l", "overall_mv", "overall_sb", "overall_slp", "day_l", "day_mv", "day_sb", "day_slp")

ML_derived_PA2 <- ML_derived_PA2 %>% filter(!is.na(overall_l))
dim(ML_derived_PA2)


ML_derived_PA2$MVPA_min <- ML_derived_PA2$overall_mv * 7 * 24 * 60 
ML_derived_PA2$MVPA_Quant <- dvmisc::quant_groups(ML_derived_PA2$MVPA_min, 4)

```




# Files from parallel processing of time-series (FieldID 90004) to generate ENMO summary of 100,000 ppl, PA1 data 
```{r, include=FALSE, message=FALSE}
enmoTSParallel_PA1 <- list.files(path="/home/yacine/survival_analysis/PA1_parallel_TS_ENMO/outputs", full.names = TRUE) %>% 
  lapply(read_csv) %>% 
  bind_rows 

enmoTSParallel_PA1$MVPA_min <- enmoTSParallel_PA1$MVPA_total* 7*24*60
enmoTSParallel_PA1$MVPA_Quant <- dvmisc::quant_groups(enmoTSParallel_PA1$MVPA_min, 4)

```


We merge the full_df and PA1 and PA2 df by eids
```{r}
full_df_PA1 <- inner_join(full_df, enmoTSParallel_PA1, by = "eid")
full_df_incl_PA1_PA2 <- inner_join(full_df_PA1, ML_derived_PA2, by = "eid")

names(full_df_incl_PA1_PA2) <- gsub("\\.x$", "_PA1", names(full_df_incl_PA1_PA2))
names(full_df_incl_PA1_PA2) <- gsub("\\.y$", "_PA2", names(full_df_incl_PA1_PA2))

#write.csv(full_df_incl_PA1_PA2, "/home/yacine/survival_analysis/full_df_with_PA.csv", row.names = FALSE)
```

# recoding some variables 
```{r}

# Recode from gender to sex 
#full_df_incl_PA1_PA2 <- full_df_incl_PA1_PA2 %>%  
#  dplyr::mutate(sex = ifelse(sex == "Man", "Male", "Female"))


# Grouping two categories into one 
#full_df_incl_PA1_PA2 <- full_df_incl_PA1_PA2 %>%  
#  dplyr::mutate(cooked_vg = ifelse(cooked_vg == "2 or 3 servings/day" | cooked_vg== "3 or 4 servings/day", "2 to 4 servings/day", cooked_vg))




```




####### Create Summary of Baseline Characteristics Table ######
```{r}


# recode binary variables 
#full_df_incl_PA1_PA2 <- full_df_incl_PA1_PA2 %>%
#  mutate(sex = recode(sex, `1` = "Male", `0` = "Female"))

MVPA_coding <- c(
  '[0,99]' = 'Q1[0,99]', 
  '(99,222]' = 'Q2(99,222]', 
  '(222,395]' = 'Q3(222,395]', 
  '(395,1.01e+04]' = 'Q4(395,1.01e+04]'
)


full_df_incl_PA1_PA2 <- full_df_incl_PA1_PA2 %>%
  mutate(MVPA_Quant_PA2 = recode(as.character(MVPA_Quant_PA2), !!!MVPA_coding))


# we seperate the full_df_incl_PA1_PA2 in 4 tables based off MVPA quarters:
df_MVPA_quarter1 <- full_df_incl_PA1_PA2 %>% filter(MVPA_Quant_PA2 == "Q1[0,99]")

df_MVPA_quarter2 <- full_df_incl_PA1_PA2 %>% filter(MVPA_Quant_PA2 == "Q2(99,222]")

df_MVPA_quarter3 <- full_df_incl_PA1_PA2 %>% filter(MVPA_Quant_PA2 == "Q3(222,395]")

df_MVPA_quarter4 <- full_df_incl_PA1_PA2 %>% filter(MVPA_Quant_PA2 == "Q4(395,1.01e+04]")


```


```{r}

full_df_incl_PA1_PA2$cooked_vg %>% table
full_df_incl_PA1_PA2$cooked_vg <- factor(full_df_incl_PA1_PA2$cooked_vg)
levels(full_df_incl_PA1_PA2$cooked_vg)
levels(full_df_incl_PA1_PA2$cooked_vg) <- list(Zero = "Zero servings/day", 'Below 2' ="< 2 servings/day", 'Between2 and 4' = "2 to 4 servings/day",               'Over 4' =  "More than 4 servings/day", 'DoNotKnow' = "Do not know") 
full_df_incl_PA1_PA2$cooked_vg %>% table


full_df_incl_PA1_PA2$fresh_fruit %>% table
full_df_incl_PA1_PA2$fresh_fruit <- factor(full_df_incl_PA1_PA2$fresh_fruit)
levels(full_df_incl_PA1_PA2$fresh_fruit)
levels(full_df_incl_PA1_PA2$fresh_fruit) <- list(Zero = "Zero servings/day", 'Below 2' ="< 2 servings/day", 'Between2 and 4' = "2 to 4 servings/day",               'Over 4' =  "More than 4 servings/day", 'DoNotKnow' = "Do not know") 
full_df_incl_PA1_PA2$fresh_fruit %>% table






# Variables to add to the table - this variable cannot be used to select colum,ns now, since cooked_veg is not rendred into summary table 
includeVar <- c(
  
  "fu_time",
  "MVPA_Quant_PA1", 
  "MVPA_Quant_PA2",
  "MVPA_min_PA1", 
  #"MVPA_min_PA2",
  "stroke", 
  "MI", 
  "age_entry_years",
  "sex", 
  "fresh_fruit", 
  "oily_fish", 
  "cooked_vg", # 1924 vars missing, hence the table function below will fail, unless 
  "alcohol_raw", 
  "processed_meat", 
  "alcohol", 
  "smoking", 
  "ethnicity", 
  "education_level",
  "tdi_quarters",
  "diabetes", 
  "BMI"
  )


d <-  full_df_incl_PA1_PA2 %>% dplyr::select(all_of(includeVar))
d <- d %>%  
  dplyr::mutate(MVPA_Quant_PA1 = factor(MVPA_Quant_PA1),
                MVPA_Quant_PA2 = factor(MVPA_Quant_PA2))



# Obesity category names can be shortened 
# Note that all vars , except alcohol, do not know and unkjnan shoudl be meet with exclusion 
dt <- d %>%  dplyr::select(
  MVPA_Quant_PA2,  
  MVPA_min_PA1, 
  MI, 
  stroke,
  age_entry_years, 
  sex, 
  oily_fish,
 cooked_vg, # the "includeVar" variable above is not used to select vars, since cooked_vg category has issue 
 fresh_fruit, 
  processed_meat, 
  alcohol, 
  smoking, 
  ethnicity, 
  education_level,  
  tdi_quarters, 
  diabetes, 
  BMI
  )



# Convert varaible names into deescriptive tabl enames 
varNameDf <- data.frame(
  varName = c("Myocardial Infarction",
              "Age at baseline",
              "MVPA min/week",
              "Race", 
              "Type II Diabetes", 
              "Deprivacation levels"
  ), 
  ChartName = c("MI", 
              "age_entry_years",
              "MVPA_min_PA1", 
              "ethnicity", 
              "diabetes", 
              "tdi_quarters")
)

tb <- dt %>%
  tbl_summary(
    by = MVPA_Quant_PA2,  
    #statistic = all_continuous() ~ "{mean} ({sd})"
    #digits = all_continuous() ~ 1,
  label = c(
     varNameDf[1, "ChartName"]~ varNameDf[1, "varName"], 
     varNameDf[2, "ChartName"]~ varNameDf[2, "varName"], 
     varNameDf[3, "ChartName"]~ varNameDf[3, "varName"], 
     varNameDf[4, "ChartName"]~ varNameDf[4, "varName"], 
   varNameDf[5, "ChartName"]~ varNameDf[5, "varName"]
)
  ) %>% 
  as_flex_table()

# cOMPRESSED table 
theme_gtsummary_compact() 

# Landscape (word format)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "landscape",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )


print(tb)

# Save 
flextable::save_as_docx("Distribution of participant characteristics by Qurtile of Moderate_Vigorous Physical Activity" = tb,  
               path = "testTable.docx", 
               pr_section = sect_properties
               )  




```


```{r}
coorplot 
pairs(inl)


library(ggcorrplot)
model.matrix(~0+., data=d) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag=FALSE, type="lower", lab=TRUE, lab_size=2)


```





##############################################################



##########
Kaplan_Meier:
  - 2 groups: PA1 and PA2 or Stroke and MI?
  - d_stroke == 1; d_MI == 1
  - end_of_fu = censoring time
  
  
  
  
## Associations with risk of incident cardiovascular disease 

In the data preparation step, we added an event status indicator at exit and a follow-up time variable. Using these, we can run a Cox model to associate overall activity with risk of incident cardiovascular disease. We'll start by using time-on-study as the timescale and set it up using the 'survival' package in R. We'll also adjust for various possible confounding variables (following the confounders used by [Ramakrishnan et al.](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1003487)):


### Regression 
```{r}

#km_stroke <- coxph(
  #Surv(fu_time, stroke) ~ overall_activity_quarters + age_entry_years + sex + ethnicity + tdi_quarters + education_level + smoking + alcohol,
  #data = full_df_incl_PA1_PA2)


fitDf <- coxph(Surv(fu_time, MI) ~ 
                 MVPA_Quant_PA2 +#+ 
                 sex + 
                 ethnicity + 
                 tdi_quarters + 
                 smoking + 
                 alcohol + 
                 processed_meat + 
                 cooked_vg + 
                 #education_level
                 #Age 
                 oily_fish, 
                data = full_df_incl_PA1_PA2)
ggsurvplot(survfit(res.cox), color = "#2E9FDF",
           ggtheme = theme_minimal())

summary(fitDf)



tbl_regression(fitDf, exponentiate = TRUE#, 
   #            label = c(
  #    varNameDf[1, "ChartName"]~ varNameDf[1, "varName"], 
   #   varNameDf[2, "ChartName"]~ varNameDf[2, "varName"], 
  #    varNameDf[3, "ChartName"]~ varNameDf[3, "varName"], 
   #   varNameDf[4, "ChartName"]~ varNameDf[4, "varName"], 
  #    varNameDf[5, "ChartName"]~ varNameDf[5, "varName"]
  #  )
)




```
  




