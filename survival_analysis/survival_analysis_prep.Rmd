---
title: "survival_analysis_prep"
author: "yacine"
date: "2024-07-16"
output:
  pdf_document: default
  html_document: default
---

We load and/or install the packages we will be using:

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Refresh environment 
rm(list= ls())
library(dplyr)
library(survival)
library(data.table)
library(readr)
library(dvmisc)
library(gtsummary)
library(gt)
library(kableExtra)
#remotes::install_github("larmarange/broom.helpers")
library(broom.helpers)
library(flextable)
library(officer)
library(ggplot2)

```

We load the data:
```{r}
#full_df <- read.csv("/home/yacine/final_df_full.csv") # full df w/o exclusions
#full_df <- read.csv("/home/yacine/UKBB_beluga/df_exc.csv") # full df with exclusions
full_df <- read.csv("/home/yacine/UKBB_beluga/df_exc_recode.csv") # full df with exclusions + recoding
```

We change the date format for the start and end accelerometer variables - which
will be crucial for later steps:
```{r}
full_df$date_start_accel <- as.Date(full_df$date_start_accel)
full_df$date_end_accel <- as.Date(full_df$date_end_accel)
```


## Follow-up time:

First we create the "end_of_fu" variable, which can be classified as date of 
stroke/MI, date of death or the end of the study (i.e. 2022):

```{r}
# we find out which death date is the latest which we will set as the "end of the study" 
# date
max_death_date_0 <- max(full_df$'date_of_death_0', na.rm = TRUE)
max_death_date_1 <- max(full_df$'date_of_death_1', na.rm = TRUE)
print(max_death_date_0)
print(max_death_date_1)

# given that we see that the max(death_date) is "2022-12-17", this will serve as 
# our "end of study" date

# we create a "end_of_study" column which indicates the end of the whole data collection:
full_df$end_of_study_date <- as.Date('2022-12-17')

# we reate a vector of all the date columns:
date_cols <- c('stroke_date', 'ischaemic_stroke_date', 'intracerebral_haemorrhage_date',
               'myocardial_infarction_date', 'STEMI_date', 'NSTEMI_date',
               'date_of_death_0', 'date_of_death_1', 'date_lost_followup',
               'end_of_study_date')



# we make sure all values within the date columns are in date format:
full_df[date_cols] <- lapply(full_df[date_cols], as.Date)

# we create the end_of_fu column by only keeping the earliest date from each rows
# within each date columns:
full_df$end_of_fu <- apply(full_df[date_cols], 1, function(x) min(x[!is.na(x)]))

#print(full_df$end_of_fu)
```

We can now create the "follow-up time" column by calculating the difference (in months) 
between the "end of follow up" and "end time of wear" columns:
```{r}
# remove NA data from date_end_accel (to do in data exclusion UKBB script?)
full_df <- full_df[!is.na(full_df$date_end_accel), ]

difftime_weeks <- difftime(full_df$end_of_fu, full_df$date_end_accel, units = "weeks")

# because the "difftime" function only allows a maximum of units in weeks, we 
# devide by 4.345 to convert to difference months
full_df$fu_time <- as.numeric(difftime_weeks) / 4.345

head(full_df$fu_time) 
#print(full_df$date_start_accel)

hist(full_df$fu_time, main = "survival time in Month")



```


##### Create binary variable for CVD (strokes and MI)

```{r}
# First we create a new column which will indicate if a participant has had: 
## a) a stroke == 1; or not == 0:
stroke_cols <- c('stroke_date', 'ischaemic_stroke_date', 'intracerebral_haemorrhage_date')

# Create the 'stroke' column
full_df$stroke <- ifelse(rowSums(!is.na(full_df[, stroke_cols ])) > 0, 1, 0)


## b) a MI == 1; or not == 0:
MI_cols <- c('myocardial_infarction_date', 'STEMI_date', 'NSTEMI_date')
full_df$MI <- ifelse(rowSums(!is.na(full_df[, MI_cols ])) > 0, 1, 0)


head(full_df$stroke)
head(full_df$MI)

# We now create a composit "CVD" column which indicates if the participants has had a
# stroke and/or MI (==1) or not (==0)
full_df <- full_df %>%
  mutate(CVD = ifelse(stroke == 1 | MI == 1, 1, 0))
```






################ GitHub PA code

# Now link data with acclerometer weekly minutes, for LPA, MVPA, and sedendary behavior.   
- There are 3 diferent accelerometric measures   
  1. PA1 - Vector magnitude based measures as calcuated from time-series of vector magnitude by UKBB 
  2. PA2 - machine-learning derived mesared, for Field ID 1020
  3. PA3 (pending) - Actigraph count-based measure, based on Freedson cutoff 


#Load derived accelerometer from UKBB, PA2 data 
```{r, include=FALSE}
ML_derived_PA2 <- fread("/home/yacine/survival_analysis/PA2_category_1020.csv")
ML_derived_PA2 <- ML_derived_PA2 %>%  dplyr::select(
  eid, 
  "40048-0.0",  
  "40049-0.0",
  "40047-0.0", 
  "40046-0.0", 
  "40044-0.0",  
  "40045-0.0",
  "40043-0.0", 
  "40042-0.0" 
)

# relabel for id, weekly light PA, weekly MVPA, weekly sleep, weekly sedentary, daily light PA, daily MVPA, daily sedentary
names(ML_derived_PA2) <- c("eid", "overall_l", "overall_mv", "overall_sb", "overall_slp", "day_l", "day_mv", "day_sb", "day_slp")

ML_derived_PA2 <- ML_derived_PA2 %>% filter(!is.na(overall_l))

dim(ML_derived_PA2)


ML_derived_PA2$MVPA_min <- ML_derived_PA2$overall_mv * 7 * 24 * 60 



ML_derived_PA2$MVPA_min <- ML_derived_PA2$overall_mv* 7*24*60
ML_derived_PA2$LPA_min <- ML_derived_PA2$overall_l* 7*24*60
ML_derived_PA2$SB_min <- ML_derived_PA2$overall_sb* 7*24*60

colnames(ML_derived_PA2) <- paste(colnames(ML_derived_PA2), "_PA2", sep = "")
colnames(ML_derived_PA2)[1] <- "eid"


```




# Files from parallel processing of time-series (FieldID 90004) to generate ENMO summary of 100,000 ppl, PA1 data 
```{r, include=FALSE, message=FALSE}
enmoTSParallel_PA1 <- list.files(path="/home/yacine/survival_analysis/PA1_parallel_TS_ENMO/outputs", full.names = TRUE) %>% 
  lapply(read_csv) %>% 
  bind_rows 

enmoTSParallel_PA1$MVPA_min <- enmoTSParallel_PA1$MVPA_total* 7*24*60
enmoTSParallel_PA1$LPA_min <- enmoTSParallel_PA1$LPA_total* 7*24*60
enmoTSParallel_PA1$SB_min <- enmoTSParallel_PA1$SB_total* 7*24*60

colnames(enmoTSParallel_PA1) <- paste(colnames(enmoTSParallel_PA1), "_PA1", sep = "")
colnames(enmoTSParallel_PA1)[1] <- "eid"




```



We merge the full_df and PA1 and PA2 df by eids
```{r}
full_df_PA <- inner_join(
  full_df, 
  enmoTSParallel_PA1 %>% 
    dplyr::select(eid, MVPA_min_PA1, LPA_min_PA1, SB_min_PA1),
  by = "eid")

full_df_PA<- inner_join(full_df_PA, 
  ML_derived_PA2 %>% 
    dplyr::select(eid, MVPA_min_PA2, LPA_min_PA2, SB_min_PA2),
  by = "eid")

```




```{r}
sum(full_df_PA$MVPA_min_PA1 > 2500 )
summary(full_df_PA$MVPA_min_PA1)

sum(full_df_PA$MVPA_min_PA2 > 2500 )
summary(full_df_PA$MVPA_min_PA2)


dim(full_df_PA)
full_df_PA <- full_df_PA %>%  filter(MVPA_min_PA2 < 2500)
full_df_PA <- full_df_PA %>%  filter(MVPA_min_PA1 < 2500)
dim(full_df_PA)



full_df_PA$MVPA_Quant_PA1 <- dvmisc::quant_groups(full_df_PA$MVPA_min_PA1, 4) %>% factor()
full_df_PA$MVPA_Quant_PA2 <- dvmisc::quant_groups(full_df_PA$MVPA_min_PA2, 4) %>% factor()

```




```{r}
# check plot to see if there are extreme data points or not 
boxplot(MVPA_min_PA1 ~ MVPA_Quant_PA1, data = full_df_PA)
boxplot(MVPA_min_PA1 ~ MVPA_Quant_PA2, data = full_df_PA)


library(ggExtra)
library(BlandAltmanLeh)
print(ggExtra::ggMarginal(
  bland.altman.plot(
    full_df_PA$MVPA_min_PA1, 
    full_df_PA$MVPA_min_PA2, 
    graph.sys = "ggplot2"
    ),
  theme_minimal(),
  type = "histogram", size=4)
)



ggplot(full_df_PA, 
       aes(x=full_df_PA$MVPA_min_PA1, 
           y=full_df_PA$MVPA_min_PA2)) + 
  geom_point(color="black", size = 0.3) +
  theme_classic() + 
  xlab("MVPA minues / week - ENMO") + 
  ylab("MVPA minues / week - ML") +  
  geom_smooth(method=lm, 
    se=FALSE, 
    linetype="dashed",
    color="grey"
  )


```



```{r}
# Re-order categories 
full_df_PA$cooked_vg %>% table
full_df_PA$cooked_vg <- factor(full_df_PA$cooked_vg)
levels(full_df_PA$cooked_vg)
levels(full_df_PA$cooked_vg) <- list( 'Less than 2 servings a day' ="< 2 servings/day", 'Between 2 and 4 servings a day' = "2 to 4 servings/day", 'More than 4 servings a day' =  "More than 4 servings/day") 
full_df_PA$cooked_vg %>% table


full_df_PA$fresh_fruit %>% table
full_df_PA$fresh_fruit <- factor(full_df_PA$fresh_fruit)
levels(full_df_PA$fresh_fruit)
levels(full_df_PA$fresh_fruit) <- list( 'Less than 2 servings a day' ="< 2 servings/day", 'Between 2 and 4 servings a day' = "2 to 4 servings/day", 'More than 4 servings a day' =  "More than 4 servings/day") 
full_df_PA$fresh_fruit %>% table


full_df_PA$smoking %>% table 
full_df_PA$smoking<- factor(full_df_PA$smoking)
levels(full_df_PA$smoking)
levels(full_df_PA$smoking) <- list( 'Never' = "Never", 
                                    'Previous' = "Previous", 
                                    'Current' =  "Current") 


full_df_PA$BMI %>% table 
full_df_PA$BMI <- factor(full_df_PA$BMI)
levels(full_df_PA$BMI)
levels(full_df_PA$BMI) <- list( "Underweight (< 18.5 kg/m2)" = "Underweight (< 18.5 kg/m2)",
                                "Normal (18.5 kg/m2 to < 25 kg/m2)" = "Normal (18.5 kg/m2 to < 25 kg/m2)" ,
                                "Overweight (25 kg/m2 to < 30 kg/m2)" = "Overweight (25 kg/m2 to < 30 kg/m2)",
                                "Obesity Class I, II or III (> 30 kg/m2)" = "Obesity Class I, II or III (> 30 kg/m2)") 

full_df_PA$alcohol %>% table 
full_df_PA$alcohol <- factor(full_df_PA$alcohol)
levels(full_df_PA$alcohol)
levels(full_df_PA$alcohol) <- list( "Never" = "Never", 
                                    "Less than once a week" = "Less than once a week", 
                                    "Once or twice a week" =  "Once or twice a week",
                                    "Three or four times a week" = "Three or four times a week",
                                    "Daily or almost daily" = "Daily or almost daily") 

full_df_PA$processed_meat %>% table 
full_df_PA$processed_meat <- factor(full_df_PA$processed_meat)
levels(full_df_PA$processed_meat)
levels(full_df_PA$processed_meat) <- list( "Less than 2 times a week" = "Less than 2 times a week", 
                                    "2-4 times a week" = "2-4 times a week", 
                                    "More than 4 times a week" =  "More than 4 times a week") 

full_df_PA$oily_fish %>% table 
full_df_PA$oily_fish <- factor(full_df_PA$oily_fish)
levels(full_df_PA$oily_fish)
levels(full_df_PA$oily_fish) <- list( "Less than 2 times a week" = "Less than 2 times a week", 
                                    "2-4 times a week" = "2-4 times a week", 
                                    "More than 4 times a week" =  "More than 4 times a week") 

full_df_PA$non_oily_fish %>% table 
full_df_PA$non_oily_fish <- factor(full_df_PA$non_oily_fish)
levels(full_df_PA$non_oily_fish)
levels(full_df_PA$non_oily_fish) <- list( "Less than 2 times a week" = "Less than 2 times a week", 
                                    "2-4 times a week" = "2-4 times a week", 
                                    "More than 4 times a week" =  "More than 4 times a week") 

full_df_PA$red_meat %>% table 
full_df_PA$red_meat <- factor(full_df_PA$red_meat)
levels(full_df_PA$red_meat)
levels(full_df_PA$red_meat) <- list( "Less than 2 times a week" = "Less than 2 times a week", 
                                    "2-4 times a week" = "2-4 times a week", 
                                    "More than 4 times a week" =  "More than 4 times a week") 

full_df_PA$education_level %>% table 
full_df_PA$education_level <- factor(full_df_PA$education_level)
levels(full_df_PA$education_level)
levels(full_df_PA$education_level) <- list( "None of the above" = "None of the above", 
                                    "O levels/GCSEs or equivalent, CSEs or equivalent" =  "O levels/GCSEs or equivalent, CSEs or equivalent",
                                    "A levels/AS, NVQ/HND/HNC or equivalent" = "A levels/AS, NVQ/HND/HNC or equivalent",
                                    "College or University degree" = "College or University degree") 


# Variables to add to the table - this variable cannot be used to select colum,ns now, since cooked_veg is not rendred into summary table 


# Obesity category names can be shortened 
# Note that all vars , except alcohol, do not know and unkjnan shoudl be meet with exclusion 
dt <- full_df_PA %>%  dplyr::select(
  fu_time, 
  MVPA_Quant_PA2,  
  MVPA_Quant_PA1,  
  MVPA_min_PA1, 
  MVPA_min_PA2, 
  MI, 
  stroke,
  age_entry_years, 
  ethnicity, 
  sex, 
  education_level,  
  tdi_quarters,
  BMI,
  diabetes, 
  smoking, 
  alcohol, 
  processed_meat, 
  red_meat,
  oily_fish,
  non_oily_fish,
  fresh_fruit,
  cooked_vg
  )



# Convert varaible names into deescriptive tabl enames 
varNameDf <- data.frame(
  varName = c("Myocardial Infarction",
              "Stroke",
              "Age",
              "MVPA min/week",
              "Race", 
              "Type II Diabetes", 
              "Deprivation index", 
              "Education", 
              "Smoking", 
              "Alcohol", 
              "Processed meat",
              "Red meat",
              "Fresh fruit", 
              "Cooked vegetables", 
              "Oily fish", 
              "Non-oily fish",
              "Sex", 
              "Follow_up time"
  ), 
  ChartName = c("MI", 
              "stroke",
              "age_entry_years",
              "MVPA_min_PA1", 
              "ethnicity", 
              "diabetes", 
              "tdi_quarters", 
              "education_level", 
              "smoking", 
              "alcohol", 
              "processed_meat", 
              "red_meat",
              "fresh_fruit", 
              "cooked_vg", 
              "oily_fish", 
              "non_oily_fish",
              "sex", 
              "fu_time")
)


var_names <- varNameDf %>% 
    select(varName, ChartName) %>% 
    tibble::deframe()

dt <- dt %>% 
    rename(!!!var_names)


tb <- dt %>%
  tbl_summary(
    by = MVPA_Quant_PA2,  
    #statistic = all_continuous() ~ "{mean} ({sd})"
    #digits = all_continuous() ~ 1,
  ) %>% 
  as_flex_table()

# cOMPRESSED table 
theme_gtsummary_compact() 

# Landscape (word format)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "landscape",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )


print(tb)

# Save 
flextable::save_as_docx("Distribution of participant characteristics by Qurtile of Moderate_Vigorous Physical Activity" = tb,  
               path = "testTable.docx", 
               pr_section = sect_properties
               )  
```


```{r}
#pairs(inl)

library(ggcorrplot)
model.matrix(~0+., data=dt) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag=FALSE, type="lower", lab=F, lab_size=2)




```





##############################################################

  
  
## Associations with risk of incident cardiovascular disease 

In the data preparation step, we added an event status indicator at exit and a follow-up time variable. Using these, we can run a Cox model to associate overall activity with risk of incident cardiovascular disease. We'll start by using time-on-study as the timescale and set it up using the 'survival' package in R. We'll also adjust for various possible confounding variables (following the confounders used by [Ramakrishnan et al.](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1003487)):


### Regression 
```{r}

# Model for PA 1 
f1 <- as.formula(Surv(`Follow_up time`,`Myocardial Infarction`) ~ 
              `MVPA_Quant_PA1`+
               Sex + 
              `Age` +
              `Race` + 
              `Type II Diabetes`+ 
              `Deprivation index`+ 
              `Education`+ 
              `Smoking`+ 
              `Alcohol`+ 
              `Processed meat`+ 
              `Fresh fruit`+ 
              `Cooked vegetables`+ 
              `Oily fish` + 
              `Non-oily fish`)

fitDf1 <- coxph(f1, data = dt)
tb1 <- tbl_regression(fitDf1, exponentiate = TRUE, label = list("MVPA_Quant_PA1" = "MVPA Quartile"))


#Model for PA 2 
#f2 <- update(f1, . ~  . + MVPA_Quant_PA2 -MVPA_Quant_PA1)
f2 <- as.formula(Surv(`Follow_up time`,`Myocardial Infarction`) ~ 
              `MVPA_Quant_PA2`+
               Sex + 
              `Age` +
              `Race` + 
              `Type II Diabetes`+ 
              `Deprivation index`+ 
              `Education`+ 
              `Smoking`+ 
              `Alcohol`+ 
              `Processed meat`+ 
              `Fresh fruit`+ 
              `Cooked vegetables`+ 
              `Oily fish` + 
              `Non-oily fish`)
fitDf2 <- coxph(f2, data = dt)
tb2 <- tbl_regression(fitDf2, exponentiate = TRUE, label = list("MVPA_Quant_PA2" = "MVPA Quartile"))





tb3 <- tbl_merge(
  tbls = list(tb1, tb2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")
)





tb3 <- as_flex_table(tb3)


# Landscape (word format)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "landscape",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Hazard ratios for icidence Myocardial Infarction" = tb3,  
  path = "HR_main_MI.docx", 
  pr_section = sect_properties
)  

```
  
  
  
  
### Regression 
```{r}

# Model for PA 1 
f1 <- as.formula(Surv(`Follow_up time`,`Stroke`) ~ 
              `MVPA_Quant_PA1`+
               Sex + 
              `Age` +
              `Race` + 
              `Type II Diabetes`+ 
              `Deprivation index`+ 
              `Education`+ 
              `Smoking`+ 
              `Alcohol`+ 
              `Processed meat`+ 
              `Fresh fruit`+ 
              `Cooked vegetables`+ 
              `Oily fish` + 
              `Non-oily fish`)

fitDf1 <- coxph(f1, data = dt)
tb1 <- tbl_regression(fitDf1, exponentiate = TRUE, label = list("MVPA_Quant_PA1" = "MVPA Quartile"))


#Model for PA 2 
#f2 <- update(f1, . ~  . + MVPA_Quant_PA2 -MVPA_Quant_PA1)
f2 <- as.formula(Surv(`Follow_up time`,`Stroke`) ~ 
              `MVPA_Quant_PA2`+
               Sex + 
              `Age` +
              `Race` + 
              `Type II Diabetes`+ 
              `Deprivation index`+ 
              `Education`+ 
              `Smoking`+ 
              `Alcohol`+ 
              `Processed meat`+ 
              `Fresh fruit`+ 
              `Cooked vegetables`+ 
              `Oily fish` + 
              `Non-oily fish`)
fitDf2 <- coxph(f2, data = dt)
tb2 <- tbl_regression(fitDf2, exponentiate = TRUE, label = list("MVPA_Quant_PA2" = "MVPA Quartile"))





tb3 <- tbl_merge(
  tbls = list(tb1, tb2),
  tab_spanner = c("**ENMO**", "**Random Forest and HMM**")
)





tb3 <- as_flex_table(tb3)


# Landscape (word format)
sect_properties <- prop_section(
  page_size = page_size(
  orient = "landscape",
  #width = 8, height = 11.7
  ),
  type = "continuous",
  page_margins = page_mar(0) 
  )

# Save 
flextable::save_as_docx("Hazard ratios for icidence stroke" = tb3,  
  path = "HR_main_Stroke.docx", 
  pr_section = sect_properties
)  

```




##########
Kaplan_Meier:
  - 2 groups: PA1 and PA2 or Stroke and MI?
  - d_stroke == 1; d_MI == 1
  - end_of_fu = censoring time
  
```{r}
  
kmfit1_mi <- survfit(Surv(`Follow_up time`, `Myocardial Infarction`) ~ `MVPA_Quant_PA1`, data = dt)
kmfit1_stroke <- survfit(Surv(`Follow_up time`, `Stroke`) ~ `MVPA_Quant_PA1`, data = dt)


kmfit2_mi <- survfit(Surv(`Follow_up time`, `Myocardial Infarction`) ~ `MVPA_Quant_PA2`, data = dt)
kmfit2_stoke <- survfit(Surv(`Follow_up time`, `Stroke`) ~ `MVPA_Quant_PA2`, data = dt)


```


```{r}


plot(kmfit1_mi, col = c("black", "grey", "blue", "red"), xlab = "Survival time", ylab = "Survival probabilities", ylim = c(1.0, 0.95))

legend("topright", c("Quarter 1", "Quarter 2", "Quarter 3", "Quarter 4"), col = c("black", "grey", "blue", "red"))


plot(kmfit1_stroke, col = c("black", "grey", "blue", "red"), xlab = "Survival time", ylab = "Survival probabilities", ylim = c(1.0, 0.95))

legend("topright", c("Quarter 1", "Quarter 2", "Quarter 3", "Quarter 4"), col = c("black", "grey", "blue", "red"))


plot(kmfit2_mi, col = c("black", "grey", "blue", "red"), xlab = "Survival time", ylab = "Survival probabilities", ylim = c(1.0, 0.95))

legend("topright", c("Quarter 1", "Quarter 2", "Quarter 3", "Quarter 4"), col = c("black", "grey", "blue", "red"))


plot(kmfit2_stoke, col = c("black", "grey", "blue", "red"), xlab = "Survival time", ylab = "Survival probabilities", ylim = c(1.0, 0.95))

legend("topright", c("Quarter 1", "Quarter 2", "Quarter 3", "Quarter 4"), col = c("black", "grey", "blue", "red"))


```

